{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymorphy2\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import TreebankWordTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = TreebankWordTokenizer()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stop_words = get_stop_words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(text, token = token):\n",
    "    wordforms = []\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub('[,.!()\"\\';:@?№—0-9«»a-z]', '', text)\n",
    "    words = token.tokenize(text)\n",
    "    for word in words:\n",
    "        word = re.sub('\\s+', ' ', word)\n",
    "        wordforms.append(word)\n",
    "    return wordforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_words(filename, stop_words = stop_words):\n",
    "    uni_words = set()\n",
    "    with open ('/Users/uliamiheeva/Desktop/hw1/texts/' + filename, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = normalization(line)\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                uni_words.add(word)\n",
    "    return uni_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(word, morph = morph):\n",
    "    lemma = morph.parse(word)[0].normal_form\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverted_index(stop_words = stop_words):\n",
    "    files = os.listdir('/Users/uliamiheeva/Desktop/hw1/texts/')\n",
    "    i = 1\n",
    "    for filename in files:\n",
    "        for word in uni_words(filename):\n",
    "            lemma = lemmatization(word)\n",
    "            if lemma:\n",
    "                if lemma in d:\n",
    "                    cur = d[lemma]\n",
    "                    if i not in cur:\n",
    "                        d[lemma] += [i]\n",
    "                else:\n",
    "                    d[lemma] = [i]\n",
    "        i += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_file(d, stop_words = stop_words):\n",
    "    with open ('invindex.csv', 'w', encoding='utf-8') as fw:\n",
    "        for line in d:\n",
    "            fw.write(line + ':' + ', '.join(map(str, d[line])) + '\\n')\n",
    "    with open ('stop_words.txt', 'w',  encoding='utf-8') as ff:\n",
    "        ff.write('\\n '.join(stop_words))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    d = inverted_index()\n",
    "    write_file(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
